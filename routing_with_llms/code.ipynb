{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "with open(\"chat_app.yaml\") as f:\n",
    "    spec1 = json.dumps(yaml.load(f, Loader=yaml.Loader))\n",
    "\n",
    "with open(\"other_app.yaml\") as f:\n",
    "    spec2 = json.dumps(yaml.load(f, Loader=yaml.Loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.openapi import OpenAPISpec\n",
    "\n",
    "parsed_spec1 = OpenAPISpec.from_text(spec1)\n",
    "parsed_spec2 = OpenAPISpec.from_text(spec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "\n",
    "openai_fns1, call_api_fn1 = openapi_spec_to_openai_fn(parsed_spec1)\n",
    "tools1 = [\n",
    "    {\"type\": \"function\", \"function\": fn}\n",
    "    for fn in openai_fns1\n",
    "]\n",
    "openai_fns2, call_api_fn2  = openapi_spec_to_openai_fn(parsed_spec2)\n",
    "tools2 = [\n",
    "    {\"type\": \"function\", \"function\": fn}\n",
    "    for fn in openai_fns2\n",
    "]\n",
    "final_tools = tools1 + tools2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "llm_with_tools = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).bind_tools(final_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = SystemMessage(content=\"Use the provided APIs to respond to this user query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_msg = HumanMessage(content=\"Gib mir alle Dokumente von John Doe\")\n",
    "messages = [sys_msg, hu_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output = llm_with_tools.invoke(input=messages)\n",
    "messages.append(llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    tool[\"function\"][\"name\"]: (\n",
    "        lambda fn_args, call_fn=(call_api_fn1 if tool[\"function\"][\"name\"].startswith(\"chat\") else call_api_fn2), tool_name=tool[\"function\"][\"name\"]: call_fn(tool_name, fn_args)\n",
    "    )\n",
    "    for tool in final_tools\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in llm_output.tool_calls:\n",
    "    selected_tool = tool_mapping[tool_call[\"name\"].lower()]\n",
    "    response = selected_tool(tool_call[\"args\"])\n",
    "\n",
    "    if hasattr(response, 'json'):\n",
    "        tool_output = response.json()\n",
    "    elif hasattr(response, 'text'):\n",
    "        tool_output = response.text\n",
    "    else:\n",
    "        tool_output = response\n",
    "\n",
    "    try:\n",
    "        tool_output = json.dumps(tool_output, indent=2, ensure_ascii=False)\n",
    "    except (TypeError, ValueError):\n",
    "        tool_output = str(tool_output)\n",
    "\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
