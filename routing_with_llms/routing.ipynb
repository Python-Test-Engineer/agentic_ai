{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "car_template = \"\"\"You are an expert in automobiles. You have extensive knowledge about car mechanics, \\\n",
    "models, and automotive technology. You provide clear and helpful answers about cars.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "restaurant_template = \"\"\"You are a knowledgeable food critic and restaurant reviewer. You have a deep understanding of \\\n",
    "different cuisines, dining experiences, and what makes a great restaurant. You answer questions about restaurants insightfully.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "technology_template = \"\"\"You are a tech expert with in-depth knowledge of the latest gadgets, software, \\\n",
    "and technological trends. You provide insightful and detailed answers about technology.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_questions = [\n",
    "    \"What is the difference between a sedan and an SUV?\",\n",
    "    \"How does a hybrid car save fuel?\",\n",
    "    \"What should I look for when buying a used car?\",\n",
    "]\n",
    "\n",
    "restaurant_questions = [\n",
    "    \"What makes a five-star restaurant exceptional?\",\n",
    "    \"How do I choose a good wine pairing for my meal?\",\n",
    "    \"What are the key elements of French cuisine?\",\n",
    "]\n",
    "\n",
    "technology_questions = [\n",
    "    \"What are the latest advancements in AI?\",\n",
    "    \"How do I secure my home network against cyber threats?\",\n",
    "    \"What should I consider when buying a new smartphone?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "car_question_embeddings = embeddings.embed_documents(car_questions)\n",
    "restaurant_question_embeddings = embeddings.embed_documents(restaurant_questions)\n",
    "technology_question_embeddings = embeddings.embed_documents(technology_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    car_similarity = cosine_similarity([query_embedding], car_question_embeddings)[0]\n",
    "    restaurant_similarity = cosine_similarity(\n",
    "        [query_embedding], restaurant_question_embeddings\n",
    "    )[0]\n",
    "    technology_similarity = cosine_similarity(\n",
    "        [query_embedding], technology_question_embeddings\n",
    "    )[0]\n",
    "\n",
    "    max_similarity = max(\n",
    "        max(car_similarity), max(restaurant_similarity), max(technology_similarity)\n",
    "    )\n",
    "\n",
    "    if max_similarity == max(car_similarity):\n",
    "        print(\"Using CAR\")\n",
    "        return PromptTemplate.from_template(car_template)\n",
    "    elif max_similarity == max(restaurant_similarity):\n",
    "        print(\"Using RESTAURANT\")\n",
    "        return PromptTemplate.from_template(restaurant_template)\n",
    "    else:\n",
    "        print(\"Using TECHNOLOGY\")\n",
    "        return PromptTemplate.from_template(technology_template)\n",
    "\n",
    "\n",
    "input_query = {\"query\": \"What's the best way to improve my cars's battery life?\"}\n",
    "prompt = prompt_router(input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"How do I identify a good vintage wine at a restaurant?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "classification_template = PromptTemplate.from_template(\n",
    "    \"\"\"You are good at classifying a question.\n",
    "    Given the user question below, classify it as either being about `Car`, `Restaurant`, or `Technology`.\n",
    "\n",
    "    <If the question is about car mechanics, models, or automotive technology, classify it as 'Car'>\n",
    "    <If the question is about cuisines, dining experiences, or restaurant services, classify it as 'Restaurant'>\n",
    "    <If the question is about gadgets, software, or technological trends, classify it as 'Technology'>\n",
    "\n",
    "    <question>\n",
    "    {question}\n",
    "    </question>\n",
    "\n",
    "    Classification:\"\"\"\n",
    ")\n",
    "\n",
    "classification_chain = classification_template | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_router(input):\n",
    "    classification = classification_chain.invoke({\"question\": input[\"query\"]})\n",
    "\n",
    "    if classification == \"Car\":\n",
    "        print(\"Using CAR\")\n",
    "        return PromptTemplate.from_template(car_template)\n",
    "    elif classification == \"Restaurant\":\n",
    "        print(\"Using RESTAURANT\")\n",
    "        return PromptTemplate.from_template(restaurant_template)\n",
    "    elif classification == \"Technology\":\n",
    "        print(\"Using TECHNOLOGY\")\n",
    "        return PromptTemplate.from_template(technology_template)\n",
    "    else:\n",
    "        print(\"Unexpected classification:\", classification)\n",
    "        return None\n",
    "\n",
    "\n",
    "input_query = {\"query\": \"What are the latest trends in electric cars?\"}\n",
    "prompt = prompt_router(input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"How do I identify a good vintage wine at a restaurant?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def classify_as_car(question: str) -> str:\n",
    "    \"\"\"Classifies the question as 'Car' if it is about car mechanics, models, or automotive technology.\n",
    "\n",
    "    Args:\n",
    "        question: The input question to classify.\n",
    "    \"\"\"\n",
    "    print(\"Function 'classify_as_car' was used.\")\n",
    "    return \"Car\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_as_restaurant(question: str) -> str:\n",
    "    \"\"\"Classifies the question as 'Restaurant' if it is about cuisines, dining experiences, or restaurant services.\n",
    "\n",
    "    Args:\n",
    "        question: The input question to classify.\n",
    "    \"\"\"\n",
    "    print(\"Function 'classify_as_restaurant' was used.\")\n",
    "    return \"Restaurant\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_as_technology(question: str) -> str:\n",
    "    \"\"\"Classifies the question as 'Technology' if it is about gadgets, software, or technological trends.\n",
    "\n",
    "    Args:\n",
    "        question: The input question to classify.\n",
    "    \"\"\"\n",
    "    print(\"Function 'classify_as_technology' was used.\")\n",
    "    return \"Technology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "query = \"How do I identify a good vintage wine at a restaurant?\"\n",
    "\n",
    "tools = [classify_as_car, classify_as_restaurant, classify_as_technology]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\n",
    "        \"classify_as_car\": classify_as_car,\n",
    "        \"classify_as_restaurant\": classify_as_restaurant,\n",
    "        \"classify_as_technology\": classify_as_technology,\n",
    "    }[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
